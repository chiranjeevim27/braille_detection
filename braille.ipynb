{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4wiJC4IVFYE"
      },
      "outputs": [],
      "source": [
        "import cv2                 \n",
        "import numpy as np         \n",
        "import os                  \n",
        "from random import shuffle\n",
        "from tqdm import tqdm  \n",
        "import tensorflow as tf \n",
        "import matplotlib.pyplot as plt\n",
        "import glob as gb\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bohZ_ikzVHv3",
        "outputId": "2ba1563a-4971-4bf9-8270-7905517db050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from opendatasets) (4.64.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (2022.12.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (2.25.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (8.0.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle->opendatasets) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download('https://www.kaggle.com/datasets/shanks0465/braille-character-dataset?select=Braille+Dataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pZwen87VPak",
        "outputId": "45e81fce-77d3-449c-c63a-b954b415c707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: chiranjeevi27\n",
            "Your Kaggle Key: ··········\n",
            "Downloading braille-character-dataset.zip to ./braille-character-dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.30M/1.30M [00:00<00:00, 118MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train='/content/braille-character-dataset/Braille Dataset/Braille Dataset'"
      ],
      "metadata": {
        "id": "r4NyqJ6YVr7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "from PIL import Image\n",
        "os.listdir(train)\n",
        "for file in os.listdir(train):\n",
        "    f_img = train+\"/\"+file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.resize((32,32))\n",
        "    img.save(f_img)"
      ],
      "metadata": {
        "id": "S6c_u3gmVwfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from shutil import copyfile\n",
        "os.mkdir('./images/')\n",
        "alpha = 'a'\n",
        "for i in range(0, 26): \n",
        "    os.mkdir('./images/' + alpha)\n",
        "    alpha = chr(ord(alpha) + 1)\n",
        "\n",
        "rootdir = '/content/braille-character-dataset/Braille Dataset/Braille Dataset/'\n",
        "for file in os.listdir(rootdir):\n",
        "    letter = file[0]\n",
        "    copyfile(rootdir+file, './images/' + letter + '/' + file)"
      ],
      "metadata": {
        "id": "K-Cf2WPHVz8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(rotation_range=20,\n",
        "                             shear_range=10,\n",
        "                             validation_split=0.2,\n",
        "                             samplewise_center=True,\n",
        "                             samplewise_std_normalization= True,\n",
        "                             width_shift_range=0.2,\n",
        "                             height_shift_range=0.2\n",
        "                             )\n",
        "train_generator = datagen.flow_from_directory('./images/',\n",
        "                                              target_size=(32,32),\n",
        "                                              subset='training',\n",
        "                                              shuffle=shuffle)\n",
        "\n",
        "val_generator = datagen.flow_from_directory('./images/',\n",
        "                                            target_size=(32,32),\n",
        "                                            subset='validation',\n",
        "                                            shuffle=shuffle)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyglOjLtWIho",
        "outputId": "4b003214-10b2-4600-9bfb-3da1ccb91dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1248 images belonging to 26 classes.\n",
            "Found 312 images belonging to 26 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pre_trained_model=tf.keras.applications.EfficientNetV2B0(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(32,32,3)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCmKh7dcWMPX",
        "outputId": "4ff9f46f-3f39-4a3f-942a-d8d8c7deacc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
            "24274472/24274472 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping\n",
        "from keras import layers as L\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "x = tf.keras.layers.Flatten()(pre_trained_model.output)\n",
        "x=tf.keras.layers.Dense(26, activation='softmax')(x)\n",
        "       \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "print(model.summary())\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
        "reduce_lr = ReduceLROnPlateau(patience=15,verbose=0)\n",
        "early_stop = EarlyStopping(patience=25,verbose=1)\n",
        "filepath=\"efficient_weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_eiODSbamnS",
        "outputId": "01cd952f-789d-44b6-cc74-0de1a12262f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_10 (InputLayer)          [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " rescaling (Rescaling)          (None, 32, 32, 3)    0           ['input_10[0][0]']               \n",
            "                                                                                                  \n",
            " normalization (Normalization)  (None, 32, 32, 3)    0           ['rescaling[0][0]']              \n",
            "                                                                                                  \n",
            " stem_conv (Conv2D)             (None, 16, 16, 32)   864         ['normalization[0][0]']          \n",
            "                                                                                                  \n",
            " stem_bn (BatchNormalization)   (None, 16, 16, 32)   128         ['stem_conv[0][0]']              \n",
            "                                                                                                  \n",
            " stem_activation (Activation)   (None, 16, 16, 32)   0           ['stem_bn[0][0]']                \n",
            "                                                                                                  \n",
            " block1a_project_conv (Conv2D)  (None, 16, 16, 16)   4608        ['stem_activation[0][0]']        \n",
            "                                                                                                  \n",
            " block1a_project_bn (BatchNorma  (None, 16, 16, 16)  64          ['block1a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block1a_project_activation (Ac  (None, 16, 16, 16)  0           ['block1a_project_bn[0][0]']     \n",
            " tivation)                                                                                        \n",
            "                                                                                                  \n",
            " block2a_expand_conv (Conv2D)   (None, 8, 8, 64)     9216        ['block1a_project_activation[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " block2a_expand_bn (BatchNormal  (None, 8, 8, 64)    256         ['block2a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block2a_expand_activation (Act  (None, 8, 8, 64)    0           ['block2a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block2a_project_conv (Conv2D)  (None, 8, 8, 32)     2048        ['block2a_expand_activation[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " block2a_project_bn (BatchNorma  (None, 8, 8, 32)    128         ['block2a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block2b_expand_conv (Conv2D)   (None, 8, 8, 128)    36864       ['block2a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_expand_bn (BatchNormal  (None, 8, 8, 128)   512         ['block2b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block2b_expand_activation (Act  (None, 8, 8, 128)   0           ['block2b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block2b_project_conv (Conv2D)  (None, 8, 8, 32)     4096        ['block2b_expand_activation[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " block2b_project_bn (BatchNorma  (None, 8, 8, 32)    128         ['block2b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block2b_drop (Dropout)         (None, 8, 8, 32)     0           ['block2b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block2b_add (Add)              (None, 8, 8, 32)     0           ['block2b_drop[0][0]',           \n",
            "                                                                  'block2a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3a_expand_conv (Conv2D)   (None, 4, 4, 128)    36864       ['block2b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block3a_expand_bn (BatchNormal  (None, 4, 4, 128)   512         ['block3a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block3a_expand_activation (Act  (None, 4, 4, 128)   0           ['block3a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block3a_project_conv (Conv2D)  (None, 4, 4, 48)     6144        ['block3a_expand_activation[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " block3a_project_bn (BatchNorma  (None, 4, 4, 48)    192         ['block3a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3b_expand_conv (Conv2D)   (None, 4, 4, 192)    82944       ['block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_expand_bn (BatchNormal  (None, 4, 4, 192)   768         ['block3b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block3b_expand_activation (Act  (None, 4, 4, 192)   0           ['block3b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block3b_project_conv (Conv2D)  (None, 4, 4, 48)     9216        ['block3b_expand_activation[0][0]\n",
            "                                                                 ']                               \n",
            "                                                                                                  \n",
            " block3b_project_bn (BatchNorma  (None, 4, 4, 48)    192         ['block3b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block3b_drop (Dropout)         (None, 4, 4, 48)     0           ['block3b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block3b_add (Add)              (None, 4, 4, 48)     0           ['block3b_drop[0][0]',           \n",
            "                                                                  'block3a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_expand_conv (Conv2D)   (None, 4, 4, 192)    9216        ['block3b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block4a_expand_bn (BatchNormal  (None, 4, 4, 192)   768         ['block4a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4a_expand_activation (Act  (None, 4, 4, 192)   0           ['block4a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4a_dwconv2 (DepthwiseConv  (None, 2, 2, 192)   1728        ['block4a_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block4a_bn (BatchNormalization  (None, 2, 2, 192)   768         ['block4a_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4a_activation (Activation  (None, 2, 2, 192)   0           ['block4a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4a_se_squeeze (GlobalAver  (None, 192)         0           ['block4a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4a_se_reshape (Reshape)   (None, 1, 1, 192)    0           ['block4a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_reduce (Conv2D)     (None, 1, 1, 12)     2316        ['block4a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4a_se_expand (Conv2D)     (None, 1, 1, 192)    2496        ['block4a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_se_excite (Multiply)   (None, 2, 2, 192)    0           ['block4a_activation[0][0]',     \n",
            "                                                                  'block4a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_conv (Conv2D)  (None, 2, 2, 96)     18432       ['block4a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4a_project_bn (BatchNorma  (None, 2, 2, 96)    384         ['block4a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4b_expand_conv (Conv2D)   (None, 2, 2, 384)    36864       ['block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_expand_bn (BatchNormal  (None, 2, 2, 384)   1536        ['block4b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4b_expand_activation (Act  (None, 2, 2, 384)   0           ['block4b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4b_dwconv2 (DepthwiseConv  (None, 2, 2, 384)   3456        ['block4b_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block4b_bn (BatchNormalization  (None, 2, 2, 384)   1536        ['block4b_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4b_activation (Activation  (None, 2, 2, 384)   0           ['block4b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4b_se_squeeze (GlobalAver  (None, 384)         0           ['block4b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4b_se_reshape (Reshape)   (None, 1, 1, 384)    0           ['block4b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_reduce (Conv2D)     (None, 1, 1, 24)     9240        ['block4b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_se_expand (Conv2D)     (None, 1, 1, 384)    9600        ['block4b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_se_excite (Multiply)   (None, 2, 2, 384)    0           ['block4b_activation[0][0]',     \n",
            "                                                                  'block4b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_conv (Conv2D)  (None, 2, 2, 96)     36864       ['block4b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4b_project_bn (BatchNorma  (None, 2, 2, 96)    384         ['block4b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4b_drop (Dropout)         (None, 2, 2, 96)     0           ['block4b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4b_add (Add)              (None, 2, 2, 96)     0           ['block4b_drop[0][0]',           \n",
            "                                                                  'block4a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_expand_conv (Conv2D)   (None, 2, 2, 384)    36864       ['block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block4c_expand_bn (BatchNormal  (None, 2, 2, 384)   1536        ['block4c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block4c_expand_activation (Act  (None, 2, 2, 384)   0           ['block4c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block4c_dwconv2 (DepthwiseConv  (None, 2, 2, 384)   3456        ['block4c_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block4c_bn (BatchNormalization  (None, 2, 2, 384)   1536        ['block4c_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4c_activation (Activation  (None, 2, 2, 384)   0           ['block4c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block4c_se_squeeze (GlobalAver  (None, 384)         0           ['block4c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block4c_se_reshape (Reshape)   (None, 1, 1, 384)    0           ['block4c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_reduce (Conv2D)     (None, 1, 1, 24)     9240        ['block4c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_se_expand (Conv2D)     (None, 1, 1, 384)    9600        ['block4c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_se_excite (Multiply)   (None, 2, 2, 384)    0           ['block4c_activation[0][0]',     \n",
            "                                                                  'block4c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_conv (Conv2D)  (None, 2, 2, 96)     36864       ['block4c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block4c_project_bn (BatchNorma  (None, 2, 2, 96)    384         ['block4c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block4c_drop (Dropout)         (None, 2, 2, 96)     0           ['block4c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block4c_add (Add)              (None, 2, 2, 96)     0           ['block4c_drop[0][0]',           \n",
            "                                                                  'block4b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_conv (Conv2D)   (None, 2, 2, 576)    55296       ['block4c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5a_expand_bn (BatchNormal  (None, 2, 2, 576)   2304        ['block5a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5a_expand_activation (Act  (None, 2, 2, 576)   0           ['block5a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5a_dwconv2 (DepthwiseConv  (None, 2, 2, 576)   5184        ['block5a_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block5a_bn (BatchNormalization  (None, 2, 2, 576)   2304        ['block5a_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5a_activation (Activation  (None, 2, 2, 576)   0           ['block5a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5a_se_squeeze (GlobalAver  (None, 576)         0           ['block5a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5a_se_reshape (Reshape)   (None, 1, 1, 576)    0           ['block5a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_reduce (Conv2D)     (None, 1, 1, 24)     13848       ['block5a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5a_se_expand (Conv2D)     (None, 1, 1, 576)    14400       ['block5a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_se_excite (Multiply)   (None, 2, 2, 576)    0           ['block5a_activation[0][0]',     \n",
            "                                                                  'block5a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_conv (Conv2D)  (None, 2, 2, 112)    64512       ['block5a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5a_project_bn (BatchNorma  (None, 2, 2, 112)   448         ['block5a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5b_expand_conv (Conv2D)   (None, 2, 2, 672)    75264       ['block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_expand_bn (BatchNormal  (None, 2, 2, 672)   2688        ['block5b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5b_expand_activation (Act  (None, 2, 2, 672)   0           ['block5b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5b_dwconv2 (DepthwiseConv  (None, 2, 2, 672)   6048        ['block5b_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block5b_bn (BatchNormalization  (None, 2, 2, 672)   2688        ['block5b_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5b_activation (Activation  (None, 2, 2, 672)   0           ['block5b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5b_se_squeeze (GlobalAver  (None, 672)         0           ['block5b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5b_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_se_excite (Multiply)   (None, 2, 2, 672)    0           ['block5b_activation[0][0]',     \n",
            "                                                                  'block5b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_conv (Conv2D)  (None, 2, 2, 112)    75264       ['block5b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5b_project_bn (BatchNorma  (None, 2, 2, 112)   448         ['block5b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5b_drop (Dropout)         (None, 2, 2, 112)    0           ['block5b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5b_add (Add)              (None, 2, 2, 112)    0           ['block5b_drop[0][0]',           \n",
            "                                                                  'block5a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_expand_conv (Conv2D)   (None, 2, 2, 672)    75264       ['block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5c_expand_bn (BatchNormal  (None, 2, 2, 672)   2688        ['block5c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5c_expand_activation (Act  (None, 2, 2, 672)   0           ['block5c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5c_dwconv2 (DepthwiseConv  (None, 2, 2, 672)   6048        ['block5c_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block5c_bn (BatchNormalization  (None, 2, 2, 672)   2688        ['block5c_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5c_activation (Activation  (None, 2, 2, 672)   0           ['block5c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5c_se_squeeze (GlobalAver  (None, 672)         0           ['block5c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5c_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_se_excite (Multiply)   (None, 2, 2, 672)    0           ['block5c_activation[0][0]',     \n",
            "                                                                  'block5c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_conv (Conv2D)  (None, 2, 2, 112)    75264       ['block5c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5c_project_bn (BatchNorma  (None, 2, 2, 112)   448         ['block5c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5c_drop (Dropout)         (None, 2, 2, 112)    0           ['block5c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5c_add (Add)              (None, 2, 2, 112)    0           ['block5c_drop[0][0]',           \n",
            "                                                                  'block5b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5d_expand_conv (Conv2D)   (None, 2, 2, 672)    75264       ['block5c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5d_expand_bn (BatchNormal  (None, 2, 2, 672)   2688        ['block5d_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5d_expand_activation (Act  (None, 2, 2, 672)   0           ['block5d_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5d_dwconv2 (DepthwiseConv  (None, 2, 2, 672)   6048        ['block5d_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block5d_bn (BatchNormalization  (None, 2, 2, 672)   2688        ['block5d_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5d_activation (Activation  (None, 2, 2, 672)   0           ['block5d_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5d_se_squeeze (GlobalAver  (None, 672)         0           ['block5d_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5d_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5d_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5d_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5d_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5d_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5d_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5d_se_excite (Multiply)   (None, 2, 2, 672)    0           ['block5d_activation[0][0]',     \n",
            "                                                                  'block5d_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5d_project_conv (Conv2D)  (None, 2, 2, 112)    75264       ['block5d_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5d_project_bn (BatchNorma  (None, 2, 2, 112)   448         ['block5d_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5d_drop (Dropout)         (None, 2, 2, 112)    0           ['block5d_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5d_add (Add)              (None, 2, 2, 112)    0           ['block5d_drop[0][0]',           \n",
            "                                                                  'block5c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5e_expand_conv (Conv2D)   (None, 2, 2, 672)    75264       ['block5d_add[0][0]']            \n",
            "                                                                                                  \n",
            " block5e_expand_bn (BatchNormal  (None, 2, 2, 672)   2688        ['block5e_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block5e_expand_activation (Act  (None, 2, 2, 672)   0           ['block5e_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block5e_dwconv2 (DepthwiseConv  (None, 2, 2, 672)   6048        ['block5e_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block5e_bn (BatchNormalization  (None, 2, 2, 672)   2688        ['block5e_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5e_activation (Activation  (None, 2, 2, 672)   0           ['block5e_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block5e_se_squeeze (GlobalAver  (None, 672)         0           ['block5e_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block5e_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block5e_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block5e_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block5e_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block5e_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block5e_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block5e_se_excite (Multiply)   (None, 2, 2, 672)    0           ['block5e_activation[0][0]',     \n",
            "                                                                  'block5e_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block5e_project_conv (Conv2D)  (None, 2, 2, 112)    75264       ['block5e_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block5e_project_bn (BatchNorma  (None, 2, 2, 112)   448         ['block5e_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block5e_drop (Dropout)         (None, 2, 2, 112)    0           ['block5e_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block5e_add (Add)              (None, 2, 2, 112)    0           ['block5e_drop[0][0]',           \n",
            "                                                                  'block5d_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_conv (Conv2D)   (None, 2, 2, 672)    75264       ['block5e_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6a_expand_bn (BatchNormal  (None, 2, 2, 672)   2688        ['block6a_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6a_expand_activation (Act  (None, 2, 2, 672)   0           ['block6a_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6a_dwconv2 (DepthwiseConv  (None, 1, 1, 672)   6048        ['block6a_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block6a_bn (BatchNormalization  (None, 1, 1, 672)   2688        ['block6a_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6a_activation (Activation  (None, 1, 1, 672)   0           ['block6a_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6a_se_squeeze (GlobalAver  (None, 672)         0           ['block6a_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6a_se_reshape (Reshape)   (None, 1, 1, 672)    0           ['block6a_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_reduce (Conv2D)     (None, 1, 1, 28)     18844       ['block6a_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6a_se_expand (Conv2D)     (None, 1, 1, 672)    19488       ['block6a_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_se_excite (Multiply)   (None, 1, 1, 672)    0           ['block6a_activation[0][0]',     \n",
            "                                                                  'block6a_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_conv (Conv2D)  (None, 1, 1, 192)    129024      ['block6a_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6a_project_bn (BatchNorma  (None, 1, 1, 192)   768         ['block6a_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6b_expand_conv (Conv2D)   (None, 1, 1, 1152)   221184      ['block6a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_expand_bn (BatchNormal  (None, 1, 1, 1152)  4608        ['block6b_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6b_expand_activation (Act  (None, 1, 1, 1152)  0           ['block6b_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6b_dwconv2 (DepthwiseConv  (None, 1, 1, 1152)  10368       ['block6b_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block6b_bn (BatchNormalization  (None, 1, 1, 1152)  4608        ['block6b_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6b_activation (Activation  (None, 1, 1, 1152)  0           ['block6b_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6b_se_squeeze (GlobalAver  (None, 1152)        0           ['block6b_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6b_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6b_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6b_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6b_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_se_excite (Multiply)   (None, 1, 1, 1152)   0           ['block6b_activation[0][0]',     \n",
            "                                                                  'block6b_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_conv (Conv2D)  (None, 1, 1, 192)    221184      ['block6b_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6b_project_bn (BatchNorma  (None, 1, 1, 192)   768         ['block6b_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6b_drop (Dropout)         (None, 1, 1, 192)    0           ['block6b_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6b_add (Add)              (None, 1, 1, 192)    0           ['block6b_drop[0][0]',           \n",
            "                                                                  'block6a_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_expand_conv (Conv2D)   (None, 1, 1, 1152)   221184      ['block6b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6c_expand_bn (BatchNormal  (None, 1, 1, 1152)  4608        ['block6c_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6c_expand_activation (Act  (None, 1, 1, 1152)  0           ['block6c_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6c_dwconv2 (DepthwiseConv  (None, 1, 1, 1152)  10368       ['block6c_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block6c_bn (BatchNormalization  (None, 1, 1, 1152)  4608        ['block6c_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6c_activation (Activation  (None, 1, 1, 1152)  0           ['block6c_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6c_se_squeeze (GlobalAver  (None, 1152)        0           ['block6c_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6c_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6c_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6c_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6c_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_se_excite (Multiply)   (None, 1, 1, 1152)   0           ['block6c_activation[0][0]',     \n",
            "                                                                  'block6c_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_conv (Conv2D)  (None, 1, 1, 192)    221184      ['block6c_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6c_project_bn (BatchNorma  (None, 1, 1, 192)   768         ['block6c_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6c_drop (Dropout)         (None, 1, 1, 192)    0           ['block6c_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6c_add (Add)              (None, 1, 1, 192)    0           ['block6c_drop[0][0]',           \n",
            "                                                                  'block6b_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6d_expand_conv (Conv2D)   (None, 1, 1, 1152)   221184      ['block6c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6d_expand_bn (BatchNormal  (None, 1, 1, 1152)  4608        ['block6d_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6d_expand_activation (Act  (None, 1, 1, 1152)  0           ['block6d_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6d_dwconv2 (DepthwiseConv  (None, 1, 1, 1152)  10368       ['block6d_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block6d_bn (BatchNormalization  (None, 1, 1, 1152)  4608        ['block6d_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6d_activation (Activation  (None, 1, 1, 1152)  0           ['block6d_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6d_se_squeeze (GlobalAver  (None, 1152)        0           ['block6d_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6d_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6d_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6d_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6d_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_se_excite (Multiply)   (None, 1, 1, 1152)   0           ['block6d_activation[0][0]',     \n",
            "                                                                  'block6d_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_conv (Conv2D)  (None, 1, 1, 192)    221184      ['block6d_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6d_project_bn (BatchNorma  (None, 1, 1, 192)   768         ['block6d_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6d_drop (Dropout)         (None, 1, 1, 192)    0           ['block6d_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6d_add (Add)              (None, 1, 1, 192)    0           ['block6d_drop[0][0]',           \n",
            "                                                                  'block6c_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6e_expand_conv (Conv2D)   (None, 1, 1, 1152)   221184      ['block6d_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6e_expand_bn (BatchNormal  (None, 1, 1, 1152)  4608        ['block6e_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6e_expand_activation (Act  (None, 1, 1, 1152)  0           ['block6e_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6e_dwconv2 (DepthwiseConv  (None, 1, 1, 1152)  10368       ['block6e_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block6e_bn (BatchNormalization  (None, 1, 1, 1152)  4608        ['block6e_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6e_activation (Activation  (None, 1, 1, 1152)  0           ['block6e_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6e_se_squeeze (GlobalAver  (None, 1152)        0           ['block6e_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6e_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6e_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6e_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6e_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6e_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6e_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6e_se_excite (Multiply)   (None, 1, 1, 1152)   0           ['block6e_activation[0][0]',     \n",
            "                                                                  'block6e_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6e_project_conv (Conv2D)  (None, 1, 1, 192)    221184      ['block6e_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6e_project_bn (BatchNorma  (None, 1, 1, 192)   768         ['block6e_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6e_drop (Dropout)         (None, 1, 1, 192)    0           ['block6e_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6e_add (Add)              (None, 1, 1, 192)    0           ['block6e_drop[0][0]',           \n",
            "                                                                  'block6d_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6f_expand_conv (Conv2D)   (None, 1, 1, 1152)   221184      ['block6e_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6f_expand_bn (BatchNormal  (None, 1, 1, 1152)  4608        ['block6f_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6f_expand_activation (Act  (None, 1, 1, 1152)  0           ['block6f_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6f_dwconv2 (DepthwiseConv  (None, 1, 1, 1152)  10368       ['block6f_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block6f_bn (BatchNormalization  (None, 1, 1, 1152)  4608        ['block6f_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6f_activation (Activation  (None, 1, 1, 1152)  0           ['block6f_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6f_se_squeeze (GlobalAver  (None, 1152)        0           ['block6f_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6f_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6f_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6f_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6f_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6f_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6f_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6f_se_excite (Multiply)   (None, 1, 1, 1152)   0           ['block6f_activation[0][0]',     \n",
            "                                                                  'block6f_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6f_project_conv (Conv2D)  (None, 1, 1, 192)    221184      ['block6f_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6f_project_bn (BatchNorma  (None, 1, 1, 192)   768         ['block6f_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6f_drop (Dropout)         (None, 1, 1, 192)    0           ['block6f_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6f_add (Add)              (None, 1, 1, 192)    0           ['block6f_drop[0][0]',           \n",
            "                                                                  'block6e_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6g_expand_conv (Conv2D)   (None, 1, 1, 1152)   221184      ['block6f_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6g_expand_bn (BatchNormal  (None, 1, 1, 1152)  4608        ['block6g_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6g_expand_activation (Act  (None, 1, 1, 1152)  0           ['block6g_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6g_dwconv2 (DepthwiseConv  (None, 1, 1, 1152)  10368       ['block6g_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block6g_bn (BatchNormalization  (None, 1, 1, 1152)  4608        ['block6g_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6g_activation (Activation  (None, 1, 1, 1152)  0           ['block6g_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6g_se_squeeze (GlobalAver  (None, 1152)        0           ['block6g_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6g_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6g_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6g_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6g_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6g_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6g_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6g_se_excite (Multiply)   (None, 1, 1, 1152)   0           ['block6g_activation[0][0]',     \n",
            "                                                                  'block6g_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6g_project_conv (Conv2D)  (None, 1, 1, 192)    221184      ['block6g_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6g_project_bn (BatchNorma  (None, 1, 1, 192)   768         ['block6g_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6g_drop (Dropout)         (None, 1, 1, 192)    0           ['block6g_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6g_add (Add)              (None, 1, 1, 192)    0           ['block6g_drop[0][0]',           \n",
            "                                                                  'block6f_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6h_expand_conv (Conv2D)   (None, 1, 1, 1152)   221184      ['block6g_add[0][0]']            \n",
            "                                                                                                  \n",
            " block6h_expand_bn (BatchNormal  (None, 1, 1, 1152)  4608        ['block6h_expand_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block6h_expand_activation (Act  (None, 1, 1, 1152)  0           ['block6h_expand_bn[0][0]']      \n",
            " ivation)                                                                                         \n",
            "                                                                                                  \n",
            " block6h_dwconv2 (DepthwiseConv  (None, 1, 1, 1152)  10368       ['block6h_expand_activation[0][0]\n",
            " 2D)                                                             ']                               \n",
            "                                                                                                  \n",
            " block6h_bn (BatchNormalization  (None, 1, 1, 1152)  4608        ['block6h_dwconv2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6h_activation (Activation  (None, 1, 1, 1152)  0           ['block6h_bn[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block6h_se_squeeze (GlobalAver  (None, 1152)        0           ['block6h_activation[0][0]']     \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " block6h_se_reshape (Reshape)   (None, 1, 1, 1152)   0           ['block6h_se_squeeze[0][0]']     \n",
            "                                                                                                  \n",
            " block6h_se_reduce (Conv2D)     (None, 1, 1, 48)     55344       ['block6h_se_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " block6h_se_expand (Conv2D)     (None, 1, 1, 1152)   56448       ['block6h_se_reduce[0][0]']      \n",
            "                                                                                                  \n",
            " block6h_se_excite (Multiply)   (None, 1, 1, 1152)   0           ['block6h_activation[0][0]',     \n",
            "                                                                  'block6h_se_expand[0][0]']      \n",
            "                                                                                                  \n",
            " block6h_project_conv (Conv2D)  (None, 1, 1, 192)    221184      ['block6h_se_excite[0][0]']      \n",
            "                                                                                                  \n",
            " block6h_project_bn (BatchNorma  (None, 1, 1, 192)   768         ['block6h_project_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block6h_drop (Dropout)         (None, 1, 1, 192)    0           ['block6h_project_bn[0][0]']     \n",
            "                                                                                                  \n",
            " block6h_add (Add)              (None, 1, 1, 192)    0           ['block6h_drop[0][0]',           \n",
            "                                                                  'block6g_add[0][0]']            \n",
            "                                                                                                  \n",
            " top_conv (Conv2D)              (None, 1, 1, 1280)   245760      ['block6h_add[0][0]']            \n",
            "                                                                                                  \n",
            " top_bn (BatchNormalization)    (None, 1, 1, 1280)   5120        ['top_conv[0][0]']               \n",
            "                                                                                                  \n",
            " top_activation (Activation)    (None, 1, 1, 1280)   0           ['top_bn[0][0]']                 \n",
            "                                                                                                  \n",
            " flatten_5 (Flatten)            (None, 1280)         0           ['top_activation[0][0]']         \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 26)           33306       ['flatten_5[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,952,618\n",
            "Trainable params: 5,892,010\n",
            "Non-trainable params: 60,608\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                              validation_data=val_generator,\n",
        "                              epochs=666,\n",
        "                              callbacks=[checkpoint,reduce_lr,early_stop],\n",
        "                              verbose=1,steps_per_epoch=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nr2o5nIa-FT",
        "outputId": "f048bf81-5e4d-4174-f770-20d75236b7d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-b7424ec8e3b5>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(train_generator,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - ETA: 0s - loss: 1.4537 - acc: 0.6500\n",
            "Epoch 1: val_acc improved from -inf to 0.17628, saving model to efficient_weights.hdf5\n",
            "15/15 [==============================] - 22s 669ms/step - loss: 1.4537 - acc: 0.6500 - val_loss: 3.0188 - val_acc: 0.1763 - lr: 0.0010\n",
            "Epoch 2/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5939 - acc: 0.8521\n",
            "Epoch 2: val_acc did not improve from 0.17628\n",
            "15/15 [==============================] - 7s 488ms/step - loss: 0.5939 - acc: 0.8521 - val_loss: 3.9476 - val_acc: 0.1058 - lr: 0.0010\n",
            "Epoch 3/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6290 - acc: 0.8167\n",
            "Epoch 3: val_acc improved from 0.17628 to 0.38462, saving model to efficient_weights.hdf5\n",
            "15/15 [==============================] - 7s 485ms/step - loss: 0.6290 - acc: 0.8167 - val_loss: 2.4459 - val_acc: 0.3846 - lr: 0.0010\n",
            "Epoch 4/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5859 - acc: 0.8417\n",
            "Epoch 4: val_acc did not improve from 0.38462\n",
            "15/15 [==============================] - 6s 433ms/step - loss: 0.5859 - acc: 0.8417 - val_loss: 2.6665 - val_acc: 0.3045 - lr: 0.0010\n",
            "Epoch 5/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6775 - acc: 0.8333\n",
            "Epoch 5: val_acc improved from 0.38462 to 0.57051, saving model to efficient_weights.hdf5\n",
            "15/15 [==============================] - 7s 486ms/step - loss: 0.6775 - acc: 0.8333 - val_loss: 1.4615 - val_acc: 0.5705 - lr: 0.0010\n",
            "Epoch 6/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6044 - acc: 0.8375\n",
            "Epoch 6: val_acc did not improve from 0.57051\n",
            "15/15 [==============================] - 7s 501ms/step - loss: 0.6044 - acc: 0.8375 - val_loss: 3.4343 - val_acc: 0.1699 - lr: 0.0010\n",
            "Epoch 7/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5139 - acc: 0.8583\n",
            "Epoch 7: val_acc improved from 0.57051 to 0.74679, saving model to efficient_weights.hdf5\n",
            "15/15 [==============================] - 7s 490ms/step - loss: 0.5139 - acc: 0.8583 - val_loss: 0.8932 - val_acc: 0.7468 - lr: 0.0010\n",
            "Epoch 8/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4978 - acc: 0.8542\n",
            "Epoch 8: val_acc improved from 0.74679 to 0.82372, saving model to efficient_weights.hdf5\n",
            "15/15 [==============================] - 8s 562ms/step - loss: 0.4978 - acc: 0.8542 - val_loss: 0.5934 - val_acc: 0.8237 - lr: 0.0010\n",
            "Epoch 9/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4113 - acc: 0.8896\n",
            "Epoch 9: val_acc did not improve from 0.82372\n",
            "15/15 [==============================] - 7s 500ms/step - loss: 0.4113 - acc: 0.8896 - val_loss: 0.9857 - val_acc: 0.6987 - lr: 0.0010\n",
            "Epoch 10/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4520 - acc: 0.8687\n",
            "Epoch 10: val_acc improved from 0.82372 to 0.91026, saving model to efficient_weights.hdf5\n",
            "15/15 [==============================] - 7s 492ms/step - loss: 0.4520 - acc: 0.8687 - val_loss: 0.3244 - val_acc: 0.9103 - lr: 0.0010\n",
            "Epoch 11/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4620 - acc: 0.8708\n",
            "Epoch 11: val_acc did not improve from 0.91026\n",
            "15/15 [==============================] - 7s 502ms/step - loss: 0.4620 - acc: 0.8708 - val_loss: 2.3193 - val_acc: 0.3878 - lr: 0.0010\n",
            "Epoch 12/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5196 - acc: 0.8542\n",
            "Epoch 12: val_acc did not improve from 0.91026\n",
            "15/15 [==============================] - 7s 497ms/step - loss: 0.5196 - acc: 0.8542 - val_loss: 1.2023 - val_acc: 0.6218 - lr: 0.0010\n",
            "Epoch 13/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4022 - acc: 0.8813\n",
            "Epoch 13: val_acc did not improve from 0.91026\n",
            "15/15 [==============================] - 7s 436ms/step - loss: 0.4022 - acc: 0.8813 - val_loss: 0.9611 - val_acc: 0.7083 - lr: 0.0010\n",
            "Epoch 14/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3795 - acc: 0.8875\n",
            "Epoch 14: val_acc did not improve from 0.91026\n",
            "15/15 [==============================] - 6s 428ms/step - loss: 0.3795 - acc: 0.8875 - val_loss: 2.2815 - val_acc: 0.3846 - lr: 0.0010\n",
            "Epoch 15/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3819 - acc: 0.8958\n",
            "Epoch 15: val_acc did not improve from 0.91026\n",
            "15/15 [==============================] - 7s 431ms/step - loss: 0.3819 - acc: 0.8958 - val_loss: 2.9527 - val_acc: 0.3141 - lr: 0.0010\n",
            "Epoch 16/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4334 - acc: 0.8833\n",
            "Epoch 16: val_acc did not improve from 0.91026\n",
            "15/15 [==============================] - 7s 483ms/step - loss: 0.4334 - acc: 0.8833 - val_loss: 2.0642 - val_acc: 0.4679 - lr: 0.0010\n",
            "Epoch 17/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4157 - acc: 0.8833\n",
            "Epoch 17: val_acc did not improve from 0.91026\n",
            "15/15 [==============================] - 7s 500ms/step - loss: 0.4157 - acc: 0.8833 - val_loss: 3.9710 - val_acc: 0.1571 - lr: 0.0010\n",
            "Epoch 18/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3797 - acc: 0.9021\n",
            "Epoch 18: val_acc did not improve from 0.91026\n",
            "15/15 [==============================] - 7s 436ms/step - loss: 0.3797 - acc: 0.9021 - val_loss: 2.1655 - val_acc: 0.3910 - lr: 0.0010\n",
            "Epoch 19/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3695 - acc: 0.8854\n",
            "Epoch 19: val_acc did not improve from 0.91026\n",
            "15/15 [==============================] - 7s 502ms/step - loss: 0.3695 - acc: 0.8854 - val_loss: 1.9971 - val_acc: 0.5128 - lr: 0.0010\n",
            "Epoch 20/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4943 - acc: 0.8625\n",
            "Epoch 20: val_acc did not improve from 0.91026\n",
            "15/15 [==============================] - 7s 436ms/step - loss: 0.4943 - acc: 0.8625 - val_loss: 0.5281 - val_acc: 0.8365 - lr: 0.0010\n",
            "Epoch 21/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4684 - acc: 0.8667\n",
            "Epoch 21: val_acc did not improve from 0.91026\n",
            "15/15 [==============================] - 7s 505ms/step - loss: 0.4684 - acc: 0.8667 - val_loss: 2.4036 - val_acc: 0.4679 - lr: 0.0010\n",
            "Epoch 22/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3017 - acc: 0.9125\n",
            "Epoch 22: val_acc did not improve from 0.91026\n",
            "15/15 [==============================] - 7s 505ms/step - loss: 0.3017 - acc: 0.9125 - val_loss: 1.4416 - val_acc: 0.5769 - lr: 0.0010\n",
            "Epoch 23/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4609 - acc: 0.8625\n",
            "Epoch 23: val_acc did not improve from 0.91026\n",
            "15/15 [==============================] - 6s 432ms/step - loss: 0.4609 - acc: 0.8625 - val_loss: 0.6896 - val_acc: 0.7981 - lr: 0.0010\n",
            "Epoch 24/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3071 - acc: 0.9104\n",
            "Epoch 24: val_acc did not improve from 0.91026\n",
            "15/15 [==============================] - 8s 507ms/step - loss: 0.3071 - acc: 0.9104 - val_loss: 3.8281 - val_acc: 0.2340 - lr: 0.0010\n",
            "Epoch 25/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2890 - acc: 0.9146\n",
            "Epoch 25: val_acc did not improve from 0.91026\n",
            "15/15 [==============================] - 7s 438ms/step - loss: 0.2890 - acc: 0.9146 - val_loss: 1.4391 - val_acc: 0.6538 - lr: 0.0010\n",
            "Epoch 26/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3167 - acc: 0.9146\n",
            "Epoch 26: val_acc did not improve from 0.91026\n",
            "15/15 [==============================] - 7s 503ms/step - loss: 0.3167 - acc: 0.9146 - val_loss: 0.6852 - val_acc: 0.8077 - lr: 1.0000e-04\n",
            "Epoch 27/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3345 - acc: 0.9062\n",
            "Epoch 27: val_acc improved from 0.91026 to 0.92949, saving model to efficient_weights.hdf5\n",
            "15/15 [==============================] - 8s 560ms/step - loss: 0.3345 - acc: 0.9062 - val_loss: 0.2215 - val_acc: 0.9295 - lr: 1.0000e-04\n",
            "Epoch 28/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2601 - acc: 0.9187\n",
            "Epoch 28: val_acc did not improve from 0.92949\n",
            "15/15 [==============================] - 7s 436ms/step - loss: 0.2601 - acc: 0.9187 - val_loss: 0.2740 - val_acc: 0.9263 - lr: 1.0000e-04\n",
            "Epoch 29/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2027 - acc: 0.9396\n",
            "Epoch 29: val_acc improved from 0.92949 to 0.95513, saving model to efficient_weights.hdf5\n",
            "15/15 [==============================] - 8s 558ms/step - loss: 0.2027 - acc: 0.9396 - val_loss: 0.1640 - val_acc: 0.9551 - lr: 1.0000e-04\n",
            "Epoch 30/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2393 - acc: 0.9187\n",
            "Epoch 30: val_acc improved from 0.95513 to 0.95833, saving model to efficient_weights.hdf5\n",
            "15/15 [==============================] - 8s 543ms/step - loss: 0.2393 - acc: 0.9187 - val_loss: 0.1127 - val_acc: 0.9583 - lr: 1.0000e-04\n",
            "Epoch 31/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2170 - acc: 0.9375\n",
            "Epoch 31: val_acc improved from 0.95833 to 0.96474, saving model to efficient_weights.hdf5\n",
            "15/15 [==============================] - 7s 492ms/step - loss: 0.2170 - acc: 0.9375 - val_loss: 0.1066 - val_acc: 0.9647 - lr: 1.0000e-04\n",
            "Epoch 32/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2174 - acc: 0.9354\n",
            "Epoch 32: val_acc did not improve from 0.96474\n",
            "15/15 [==============================] - 8s 508ms/step - loss: 0.2174 - acc: 0.9354 - val_loss: 0.1369 - val_acc: 0.9551 - lr: 1.0000e-04\n",
            "Epoch 33/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2048 - acc: 0.9271\n",
            "Epoch 33: val_acc did not improve from 0.96474\n",
            "15/15 [==============================] - 7s 503ms/step - loss: 0.2048 - acc: 0.9271 - val_loss: 0.1302 - val_acc: 0.9551 - lr: 1.0000e-04\n",
            "Epoch 34/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2211 - acc: 0.9375\n",
            "Epoch 34: val_acc did not improve from 0.96474\n",
            "15/15 [==============================] - 7s 437ms/step - loss: 0.2211 - acc: 0.9375 - val_loss: 0.2901 - val_acc: 0.9167 - lr: 1.0000e-04\n",
            "Epoch 35/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1859 - acc: 0.9438\n",
            "Epoch 35: val_acc improved from 0.96474 to 0.96795, saving model to efficient_weights.hdf5\n",
            "15/15 [==============================] - 7s 496ms/step - loss: 0.1859 - acc: 0.9438 - val_loss: 0.1231 - val_acc: 0.9679 - lr: 1.0000e-04\n",
            "Epoch 36/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2351 - acc: 0.9271\n",
            "Epoch 36: val_acc did not improve from 0.96795\n",
            "15/15 [==============================] - 7s 458ms/step - loss: 0.2351 - acc: 0.9271 - val_loss: 0.1208 - val_acc: 0.9615 - lr: 1.0000e-04\n",
            "Epoch 37/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1449 - acc: 0.9500\n",
            "Epoch 37: val_acc did not improve from 0.96795\n",
            "15/15 [==============================] - 7s 504ms/step - loss: 0.1449 - acc: 0.9500 - val_loss: 0.1620 - val_acc: 0.9455 - lr: 1.0000e-04\n",
            "Epoch 38/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1757 - acc: 0.9333\n",
            "Epoch 38: val_acc did not improve from 0.96795\n",
            "15/15 [==============================] - 7s 435ms/step - loss: 0.1757 - acc: 0.9333 - val_loss: 0.1050 - val_acc: 0.9615 - lr: 1.0000e-04\n",
            "Epoch 39/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2023 - acc: 0.9479\n",
            "Epoch 39: val_acc did not improve from 0.96795\n",
            "15/15 [==============================] - 7s 499ms/step - loss: 0.2023 - acc: 0.9479 - val_loss: 0.1346 - val_acc: 0.9551 - lr: 1.0000e-04\n",
            "Epoch 40/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1518 - acc: 0.9604\n",
            "Epoch 40: val_acc did not improve from 0.96795\n",
            "15/15 [==============================] - 8s 505ms/step - loss: 0.1518 - acc: 0.9604 - val_loss: 0.1119 - val_acc: 0.9615 - lr: 1.0000e-04\n",
            "Epoch 41/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1665 - acc: 0.9604\n",
            "Epoch 41: val_acc did not improve from 0.96795\n",
            "15/15 [==============================] - 7s 436ms/step - loss: 0.1665 - acc: 0.9604 - val_loss: 0.1350 - val_acc: 0.9583 - lr: 1.0000e-04\n",
            "Epoch 42/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1373 - acc: 0.9583\n",
            "Epoch 42: val_acc did not improve from 0.96795\n",
            "15/15 [==============================] - 7s 501ms/step - loss: 0.1373 - acc: 0.9583 - val_loss: 0.1989 - val_acc: 0.9295 - lr: 1.0000e-04\n",
            "Epoch 43/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1632 - acc: 0.9500\n",
            "Epoch 43: val_acc improved from 0.96795 to 0.97436, saving model to efficient_weights.hdf5\n",
            "15/15 [==============================] - 8s 522ms/step - loss: 0.1632 - acc: 0.9500 - val_loss: 0.0941 - val_acc: 0.9744 - lr: 1.0000e-04\n",
            "Epoch 44/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1588 - acc: 0.9458\n",
            "Epoch 44: val_acc did not improve from 0.97436\n",
            "15/15 [==============================] - 7s 453ms/step - loss: 0.1588 - acc: 0.9458 - val_loss: 0.1130 - val_acc: 0.9679 - lr: 1.0000e-04\n",
            "Epoch 45/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1959 - acc: 0.9354\n",
            "Epoch 45: val_acc did not improve from 0.97436\n",
            "15/15 [==============================] - 7s 504ms/step - loss: 0.1959 - acc: 0.9354 - val_loss: 0.0950 - val_acc: 0.9583 - lr: 1.0000e-04\n",
            "Epoch 46/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1218 - acc: 0.9625\n",
            "Epoch 46: val_acc did not improve from 0.97436\n",
            "15/15 [==============================] - 7s 502ms/step - loss: 0.1218 - acc: 0.9625 - val_loss: 0.1114 - val_acc: 0.9647 - lr: 1.0000e-04\n",
            "Epoch 47/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1336 - acc: 0.9458\n",
            "Epoch 47: val_acc did not improve from 0.97436\n",
            "15/15 [==============================] - 7s 464ms/step - loss: 0.1336 - acc: 0.9458 - val_loss: 0.1811 - val_acc: 0.9423 - lr: 1.0000e-04\n",
            "Epoch 48/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1528 - acc: 0.9417\n",
            "Epoch 48: val_acc did not improve from 0.97436\n",
            "15/15 [==============================] - 7s 459ms/step - loss: 0.1528 - acc: 0.9417 - val_loss: 0.1010 - val_acc: 0.9551 - lr: 1.0000e-04\n",
            "Epoch 49/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1202 - acc: 0.9563\n",
            "Epoch 49: val_acc did not improve from 0.97436\n",
            "15/15 [==============================] - 7s 504ms/step - loss: 0.1202 - acc: 0.9563 - val_loss: 0.1724 - val_acc: 0.9487 - lr: 1.0000e-04\n",
            "Epoch 50/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1677 - acc: 0.9458\n",
            "Epoch 50: val_acc improved from 0.97436 to 0.98397, saving model to efficient_weights.hdf5\n",
            "15/15 [==============================] - 8s 562ms/step - loss: 0.1677 - acc: 0.9458 - val_loss: 0.0837 - val_acc: 0.9840 - lr: 1.0000e-04\n",
            "Epoch 51/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1153 - acc: 0.9604\n",
            "Epoch 51: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 454ms/step - loss: 0.1153 - acc: 0.9604 - val_loss: 0.1284 - val_acc: 0.9647 - lr: 1.0000e-04\n",
            "Epoch 52/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1972 - acc: 0.9500\n",
            "Epoch 52: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 434ms/step - loss: 0.1972 - acc: 0.9500 - val_loss: 0.1136 - val_acc: 0.9615 - lr: 1.0000e-04\n",
            "Epoch 53/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1940 - acc: 0.9417\n",
            "Epoch 53: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 436ms/step - loss: 0.1940 - acc: 0.9417 - val_loss: 0.1857 - val_acc: 0.9519 - lr: 1.0000e-04\n",
            "Epoch 54/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1526 - acc: 0.9521\n",
            "Epoch 54: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 441ms/step - loss: 0.1526 - acc: 0.9521 - val_loss: 0.0882 - val_acc: 0.9615 - lr: 1.0000e-04\n",
            "Epoch 55/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1440 - acc: 0.9625\n",
            "Epoch 55: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 8s 506ms/step - loss: 0.1440 - acc: 0.9625 - val_loss: 0.0877 - val_acc: 0.9679 - lr: 1.0000e-04\n",
            "Epoch 56/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1590 - acc: 0.9500\n",
            "Epoch 56: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 437ms/step - loss: 0.1590 - acc: 0.9500 - val_loss: 0.0835 - val_acc: 0.9679 - lr: 1.0000e-04\n",
            "Epoch 57/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1479 - acc: 0.9542\n",
            "Epoch 57: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 436ms/step - loss: 0.1479 - acc: 0.9542 - val_loss: 0.1407 - val_acc: 0.9455 - lr: 1.0000e-04\n",
            "Epoch 58/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1587 - acc: 0.9542\n",
            "Epoch 58: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 8s 504ms/step - loss: 0.1587 - acc: 0.9542 - val_loss: 0.0854 - val_acc: 0.9712 - lr: 1.0000e-04\n",
            "Epoch 59/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1198 - acc: 0.9563\n",
            "Epoch 59: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 492ms/step - loss: 0.1198 - acc: 0.9563 - val_loss: 0.1266 - val_acc: 0.9583 - lr: 1.0000e-04\n",
            "Epoch 60/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1446 - acc: 0.9563\n",
            "Epoch 60: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 435ms/step - loss: 0.1446 - acc: 0.9563 - val_loss: 0.1008 - val_acc: 0.9583 - lr: 1.0000e-04\n",
            "Epoch 61/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0882 - acc: 0.9708\n",
            "Epoch 61: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 433ms/step - loss: 0.0882 - acc: 0.9708 - val_loss: 0.1128 - val_acc: 0.9647 - lr: 1.0000e-04\n",
            "Epoch 62/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1523 - acc: 0.9604\n",
            "Epoch 62: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 500ms/step - loss: 0.1523 - acc: 0.9604 - val_loss: 0.1227 - val_acc: 0.9519 - lr: 1.0000e-04\n",
            "Epoch 63/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1871 - acc: 0.9354\n",
            "Epoch 63: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 436ms/step - loss: 0.1871 - acc: 0.9354 - val_loss: 0.1141 - val_acc: 0.9679 - lr: 1.0000e-04\n",
            "Epoch 64/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1936 - acc: 0.9438\n",
            "Epoch 64: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 501ms/step - loss: 0.1936 - acc: 0.9438 - val_loss: 0.0992 - val_acc: 0.9679 - lr: 1.0000e-04\n",
            "Epoch 65/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1969 - acc: 0.9354\n",
            "Epoch 65: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 501ms/step - loss: 0.1969 - acc: 0.9354 - val_loss: 0.0926 - val_acc: 0.9647 - lr: 1.0000e-04\n",
            "Epoch 66/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1282 - acc: 0.9583\n",
            "Epoch 66: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 481ms/step - loss: 0.1282 - acc: 0.9583 - val_loss: 0.1275 - val_acc: 0.9647 - lr: 1.0000e-04\n",
            "Epoch 67/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1493 - acc: 0.9458\n",
            "Epoch 67: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 437ms/step - loss: 0.1493 - acc: 0.9458 - val_loss: 0.0826 - val_acc: 0.9808 - lr: 1.0000e-04\n",
            "Epoch 68/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1787 - acc: 0.9438\n",
            "Epoch 68: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 438ms/step - loss: 0.1787 - acc: 0.9438 - val_loss: 0.1172 - val_acc: 0.9712 - lr: 1.0000e-04\n",
            "Epoch 69/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1393 - acc: 0.9583\n",
            "Epoch 69: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 8s 506ms/step - loss: 0.1393 - acc: 0.9583 - val_loss: 0.1091 - val_acc: 0.9712 - lr: 1.0000e-04\n",
            "Epoch 70/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1694 - acc: 0.9604\n",
            "Epoch 70: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 6s 433ms/step - loss: 0.1694 - acc: 0.9604 - val_loss: 0.0800 - val_acc: 0.9679 - lr: 1.0000e-04\n",
            "Epoch 71/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1772 - acc: 0.9375\n",
            "Epoch 71: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 435ms/step - loss: 0.1772 - acc: 0.9375 - val_loss: 0.0890 - val_acc: 0.9679 - lr: 1.0000e-04\n",
            "Epoch 72/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1424 - acc: 0.9604\n",
            "Epoch 72: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 8s 503ms/step - loss: 0.1424 - acc: 0.9604 - val_loss: 0.0777 - val_acc: 0.9808 - lr: 1.0000e-04\n",
            "Epoch 73/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1224 - acc: 0.9604\n",
            "Epoch 73: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 439ms/step - loss: 0.1224 - acc: 0.9604 - val_loss: 0.0696 - val_acc: 0.9712 - lr: 1.0000e-04\n",
            "Epoch 74/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1538 - acc: 0.9521\n",
            "Epoch 74: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 435ms/step - loss: 0.1538 - acc: 0.9521 - val_loss: 0.0762 - val_acc: 0.9808 - lr: 1.0000e-04\n",
            "Epoch 75/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1458 - acc: 0.9625\n",
            "Epoch 75: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 436ms/step - loss: 0.1458 - acc: 0.9625 - val_loss: 0.0754 - val_acc: 0.9744 - lr: 1.0000e-04\n",
            "Epoch 76/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1339 - acc: 0.9625\n",
            "Epoch 76: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 503ms/step - loss: 0.1339 - acc: 0.9625 - val_loss: 0.1118 - val_acc: 0.9647 - lr: 1.0000e-04\n",
            "Epoch 77/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0954 - acc: 0.9688\n",
            "Epoch 77: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 436ms/step - loss: 0.0954 - acc: 0.9688 - val_loss: 0.0743 - val_acc: 0.9776 - lr: 1.0000e-04\n",
            "Epoch 78/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0991 - acc: 0.9646\n",
            "Epoch 78: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 8s 507ms/step - loss: 0.0991 - acc: 0.9646 - val_loss: 0.0808 - val_acc: 0.9712 - lr: 1.0000e-04\n",
            "Epoch 79/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1407 - acc: 0.9521\n",
            "Epoch 79: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 6s 433ms/step - loss: 0.1407 - acc: 0.9521 - val_loss: 0.0887 - val_acc: 0.9712 - lr: 1.0000e-04\n",
            "Epoch 80/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1125 - acc: 0.9646\n",
            "Epoch 80: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 6s 433ms/step - loss: 0.1125 - acc: 0.9646 - val_loss: 0.0876 - val_acc: 0.9712 - lr: 1.0000e-04\n",
            "Epoch 81/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1195 - acc: 0.9667\n",
            "Epoch 81: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 8s 506ms/step - loss: 0.1195 - acc: 0.9667 - val_loss: 0.0723 - val_acc: 0.9712 - lr: 1.0000e-04\n",
            "Epoch 82/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1785 - acc: 0.9542\n",
            "Epoch 82: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 434ms/step - loss: 0.1785 - acc: 0.9542 - val_loss: 0.0900 - val_acc: 0.9712 - lr: 1.0000e-04\n",
            "Epoch 83/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1603 - acc: 0.9500\n",
            "Epoch 83: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 6s 433ms/step - loss: 0.1603 - acc: 0.9500 - val_loss: 0.1053 - val_acc: 0.9647 - lr: 1.0000e-04\n",
            "Epoch 84/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0837 - acc: 0.9708\n",
            "Epoch 84: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 436ms/step - loss: 0.0837 - acc: 0.9708 - val_loss: 0.0672 - val_acc: 0.9840 - lr: 1.0000e-04\n",
            "Epoch 85/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1132 - acc: 0.9625\n",
            "Epoch 85: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 465ms/step - loss: 0.1132 - acc: 0.9625 - val_loss: 0.1174 - val_acc: 0.9712 - lr: 1.0000e-04\n",
            "Epoch 86/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0940 - acc: 0.9729\n",
            "Epoch 86: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 505ms/step - loss: 0.0940 - acc: 0.9729 - val_loss: 0.1213 - val_acc: 0.9679 - lr: 1.0000e-04\n",
            "Epoch 87/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1047 - acc: 0.9604\n",
            "Epoch 87: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 436ms/step - loss: 0.1047 - acc: 0.9604 - val_loss: 0.0816 - val_acc: 0.9679 - lr: 1.0000e-04\n",
            "Epoch 88/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1126 - acc: 0.9563\n",
            "Epoch 88: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 492ms/step - loss: 0.1126 - acc: 0.9563 - val_loss: 0.1082 - val_acc: 0.9647 - lr: 1.0000e-04\n",
            "Epoch 89/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1744 - acc: 0.9500\n",
            "Epoch 89: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 502ms/step - loss: 0.1744 - acc: 0.9500 - val_loss: 0.0857 - val_acc: 0.9679 - lr: 1.0000e-04\n",
            "Epoch 90/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1549 - acc: 0.9500\n",
            "Epoch 90: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 435ms/step - loss: 0.1549 - acc: 0.9500 - val_loss: 0.0520 - val_acc: 0.9808 - lr: 1.0000e-04\n",
            "Epoch 91/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1056 - acc: 0.9604\n",
            "Epoch 91: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 504ms/step - loss: 0.1056 - acc: 0.9604 - val_loss: 0.0614 - val_acc: 0.9776 - lr: 1.0000e-04\n",
            "Epoch 92/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0793 - acc: 0.9750\n",
            "Epoch 92: val_acc improved from 0.98397 to 0.98718, saving model to efficient_weights.hdf5\n",
            "15/15 [==============================] - 8s 535ms/step - loss: 0.0793 - acc: 0.9750 - val_loss: 0.0354 - val_acc: 0.9872 - lr: 1.0000e-04\n",
            "Epoch 93/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0765 - acc: 0.9812\n",
            "Epoch 93: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 7s 441ms/step - loss: 0.0765 - acc: 0.9812 - val_loss: 0.0983 - val_acc: 0.9679 - lr: 1.0000e-04\n",
            "Epoch 94/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1099 - acc: 0.9729\n",
            "Epoch 94: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 7s 435ms/step - loss: 0.1099 - acc: 0.9729 - val_loss: 0.0943 - val_acc: 0.9744 - lr: 1.0000e-04\n",
            "Epoch 95/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0840 - acc: 0.9646\n",
            "Epoch 95: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 8s 506ms/step - loss: 0.0840 - acc: 0.9646 - val_loss: 0.0746 - val_acc: 0.9744 - lr: 1.0000e-04\n",
            "Epoch 96/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1419 - acc: 0.9563\n",
            "Epoch 96: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 7s 441ms/step - loss: 0.1419 - acc: 0.9563 - val_loss: 0.0713 - val_acc: 0.9776 - lr: 1.0000e-04\n",
            "Epoch 97/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1446 - acc: 0.9500\n",
            "Epoch 97: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 7s 435ms/step - loss: 0.1446 - acc: 0.9500 - val_loss: 0.0774 - val_acc: 0.9808 - lr: 1.0000e-04\n",
            "Epoch 98/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1204 - acc: 0.9625\n",
            "Epoch 98: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 7s 446ms/step - loss: 0.1204 - acc: 0.9625 - val_loss: 0.0770 - val_acc: 0.9712 - lr: 1.0000e-04\n",
            "Epoch 99/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0928 - acc: 0.9729\n",
            "Epoch 99: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 7s 505ms/step - loss: 0.0928 - acc: 0.9729 - val_loss: 0.1049 - val_acc: 0.9615 - lr: 1.0000e-04\n",
            "Epoch 100/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0876 - acc: 0.9708\n",
            "Epoch 100: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 7s 436ms/step - loss: 0.0876 - acc: 0.9708 - val_loss: 0.0929 - val_acc: 0.9712 - lr: 1.0000e-04\n",
            "Epoch 101/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1239 - acc: 0.9688\n",
            "Epoch 101: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 7s 505ms/step - loss: 0.1239 - acc: 0.9688 - val_loss: 0.1346 - val_acc: 0.9615 - lr: 1.0000e-04\n",
            "Epoch 102/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0658 - acc: 0.9833\n",
            "Epoch 102: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 7s 505ms/step - loss: 0.0658 - acc: 0.9833 - val_loss: 0.0676 - val_acc: 0.9776 - lr: 1.0000e-04\n",
            "Epoch 103/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1429 - acc: 0.9604\n",
            "Epoch 103: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 7s 435ms/step - loss: 0.1429 - acc: 0.9604 - val_loss: 0.0713 - val_acc: 0.9712 - lr: 1.0000e-04\n",
            "Epoch 104/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0900 - acc: 0.9667\n",
            "Epoch 104: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 7s 505ms/step - loss: 0.0900 - acc: 0.9667 - val_loss: 0.1205 - val_acc: 0.9487 - lr: 1.0000e-04\n",
            "Epoch 105/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1177 - acc: 0.9604\n",
            "Epoch 105: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 8s 507ms/step - loss: 0.1177 - acc: 0.9604 - val_loss: 0.0430 - val_acc: 0.9872 - lr: 1.0000e-04\n",
            "Epoch 106/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1149 - acc: 0.9667\n",
            "Epoch 106: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 7s 486ms/step - loss: 0.1149 - acc: 0.9667 - val_loss: 0.0753 - val_acc: 0.9679 - lr: 1.0000e-04\n",
            "Epoch 107/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1050 - acc: 0.9646\n",
            "Epoch 107: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 7s 446ms/step - loss: 0.1050 - acc: 0.9646 - val_loss: 0.1130 - val_acc: 0.9519 - lr: 1.0000e-04\n",
            "Epoch 108/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1553 - acc: 0.9479\n",
            "Epoch 108: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 7s 502ms/step - loss: 0.1553 - acc: 0.9479 - val_loss: 0.1044 - val_acc: 0.9679 - lr: 1.0000e-05\n",
            "Epoch 109/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0807 - acc: 0.9792\n",
            "Epoch 109: val_acc improved from 0.98718 to 0.99679, saving model to efficient_weights.hdf5\n",
            "15/15 [==============================] - 7s 499ms/step - loss: 0.0807 - acc: 0.9792 - val_loss: 0.0222 - val_acc: 0.9968 - lr: 1.0000e-05\n",
            "Epoch 110/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1425 - acc: 0.9521\n",
            "Epoch 110: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 441ms/step - loss: 0.1425 - acc: 0.9521 - val_loss: 0.0610 - val_acc: 0.9808 - lr: 1.0000e-05\n",
            "Epoch 111/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1011 - acc: 0.9729\n",
            "Epoch 111: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 504ms/step - loss: 0.1011 - acc: 0.9729 - val_loss: 0.0745 - val_acc: 0.9808 - lr: 1.0000e-05\n",
            "Epoch 112/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0751 - acc: 0.9771\n",
            "Epoch 112: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 486ms/step - loss: 0.0751 - acc: 0.9771 - val_loss: 0.0870 - val_acc: 0.9647 - lr: 1.0000e-05\n",
            "Epoch 113/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0839 - acc: 0.9646\n",
            "Epoch 113: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 448ms/step - loss: 0.0839 - acc: 0.9646 - val_loss: 0.0735 - val_acc: 0.9776 - lr: 1.0000e-05\n",
            "Epoch 114/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0885 - acc: 0.9646\n",
            "Epoch 114: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 8s 506ms/step - loss: 0.0885 - acc: 0.9646 - val_loss: 0.0874 - val_acc: 0.9679 - lr: 1.0000e-05\n",
            "Epoch 115/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0769 - acc: 0.9771\n",
            "Epoch 115: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 436ms/step - loss: 0.0769 - acc: 0.9771 - val_loss: 0.0554 - val_acc: 0.9744 - lr: 1.0000e-05\n",
            "Epoch 116/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0944 - acc: 0.9729\n",
            "Epoch 116: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 489ms/step - loss: 0.0944 - acc: 0.9729 - val_loss: 0.0876 - val_acc: 0.9615 - lr: 1.0000e-05\n",
            "Epoch 117/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0861 - acc: 0.9729\n",
            "Epoch 117: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 8s 506ms/step - loss: 0.0861 - acc: 0.9729 - val_loss: 0.0943 - val_acc: 0.9744 - lr: 1.0000e-05\n",
            "Epoch 118/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1318 - acc: 0.9563\n",
            "Epoch 118: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 8s 510ms/step - loss: 0.1318 - acc: 0.9563 - val_loss: 0.0355 - val_acc: 0.9904 - lr: 1.0000e-05\n",
            "Epoch 119/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0750 - acc: 0.9771\n",
            "Epoch 119: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 441ms/step - loss: 0.0750 - acc: 0.9771 - val_loss: 0.0638 - val_acc: 0.9712 - lr: 1.0000e-05\n",
            "Epoch 120/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0893 - acc: 0.9771\n",
            "Epoch 120: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 8s 513ms/step - loss: 0.0893 - acc: 0.9771 - val_loss: 0.0789 - val_acc: 0.9679 - lr: 1.0000e-05\n",
            "Epoch 121/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1238 - acc: 0.9625\n",
            "Epoch 121: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 439ms/step - loss: 0.1238 - acc: 0.9625 - val_loss: 0.0652 - val_acc: 0.9808 - lr: 1.0000e-05\n",
            "Epoch 122/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0826 - acc: 0.9792\n",
            "Epoch 122: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 8s 507ms/step - loss: 0.0826 - acc: 0.9792 - val_loss: 0.0668 - val_acc: 0.9679 - lr: 1.0000e-05\n",
            "Epoch 123/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1062 - acc: 0.9625\n",
            "Epoch 123: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 444ms/step - loss: 0.1062 - acc: 0.9625 - val_loss: 0.0674 - val_acc: 0.9776 - lr: 1.0000e-05\n",
            "Epoch 124/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0964 - acc: 0.9729\n",
            "Epoch 124: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 8s 498ms/step - loss: 0.0964 - acc: 0.9729 - val_loss: 0.0771 - val_acc: 0.9647 - lr: 1.0000e-05\n",
            "Epoch 125/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0916 - acc: 0.9771\n",
            "Epoch 125: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 8s 508ms/step - loss: 0.0916 - acc: 0.9771 - val_loss: 0.0534 - val_acc: 0.9872 - lr: 1.0000e-06\n",
            "Epoch 126/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1009 - acc: 0.9708\n",
            "Epoch 126: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 437ms/step - loss: 0.1009 - acc: 0.9708 - val_loss: 0.0488 - val_acc: 0.9872 - lr: 1.0000e-06\n",
            "Epoch 127/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1073 - acc: 0.9604\n",
            "Epoch 127: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 8s 509ms/step - loss: 0.1073 - acc: 0.9604 - val_loss: 0.0649 - val_acc: 0.9840 - lr: 1.0000e-06\n",
            "Epoch 128/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1090 - acc: 0.9646\n",
            "Epoch 128: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 462ms/step - loss: 0.1090 - acc: 0.9646 - val_loss: 0.0552 - val_acc: 0.9808 - lr: 1.0000e-06\n",
            "Epoch 129/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0955 - acc: 0.9688\n",
            "Epoch 129: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 437ms/step - loss: 0.0955 - acc: 0.9688 - val_loss: 0.0820 - val_acc: 0.9647 - lr: 1.0000e-06\n",
            "Epoch 130/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0809 - acc: 0.9708\n",
            "Epoch 130: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 436ms/step - loss: 0.0809 - acc: 0.9708 - val_loss: 0.0639 - val_acc: 0.9904 - lr: 1.0000e-06\n",
            "Epoch 131/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1145 - acc: 0.9688\n",
            "Epoch 131: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 504ms/step - loss: 0.1145 - acc: 0.9688 - val_loss: 0.0220 - val_acc: 0.9904 - lr: 1.0000e-06\n",
            "Epoch 132/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1182 - acc: 0.9667\n",
            "Epoch 132: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 439ms/step - loss: 0.1182 - acc: 0.9667 - val_loss: 0.1096 - val_acc: 0.9744 - lr: 1.0000e-06\n",
            "Epoch 133/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1157 - acc: 0.9646\n",
            "Epoch 133: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 8s 510ms/step - loss: 0.1157 - acc: 0.9646 - val_loss: 0.1199 - val_acc: 0.9615 - lr: 1.0000e-06\n",
            "Epoch 134/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1169 - acc: 0.9646\n",
            "Epoch 134: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 468ms/step - loss: 0.1169 - acc: 0.9646 - val_loss: 0.0670 - val_acc: 0.9712 - lr: 1.0000e-06\n",
            "Epoch 135/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1308 - acc: 0.9625\n",
            "Epoch 135: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 471ms/step - loss: 0.1308 - acc: 0.9625 - val_loss: 0.0925 - val_acc: 0.9776 - lr: 1.0000e-06\n",
            "Epoch 136/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1641 - acc: 0.9563\n",
            "Epoch 136: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 8s 507ms/step - loss: 0.1641 - acc: 0.9563 - val_loss: 0.0536 - val_acc: 0.9712 - lr: 1.0000e-06\n",
            "Epoch 137/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1156 - acc: 0.9708\n",
            "Epoch 137: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 441ms/step - loss: 0.1156 - acc: 0.9708 - val_loss: 0.0826 - val_acc: 0.9679 - lr: 1.0000e-06\n",
            "Epoch 138/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1182 - acc: 0.9646\n",
            "Epoch 138: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 488ms/step - loss: 0.1182 - acc: 0.9646 - val_loss: 0.0646 - val_acc: 0.9808 - lr: 1.0000e-06\n",
            "Epoch 139/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1154 - acc: 0.9604\n",
            "Epoch 139: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 8s 507ms/step - loss: 0.1154 - acc: 0.9604 - val_loss: 0.0712 - val_acc: 0.9647 - lr: 1.0000e-06\n",
            "Epoch 140/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0793 - acc: 0.9750\n",
            "Epoch 140: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 443ms/step - loss: 0.0793 - acc: 0.9750 - val_loss: 0.0536 - val_acc: 0.9840 - lr: 1.0000e-06\n",
            "Epoch 141/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1021 - acc: 0.9604\n",
            "Epoch 141: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 503ms/step - loss: 0.1021 - acc: 0.9604 - val_loss: 0.0471 - val_acc: 0.9744 - lr: 1.0000e-06\n",
            "Epoch 142/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1221 - acc: 0.9583\n",
            "Epoch 142: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 440ms/step - loss: 0.1221 - acc: 0.9583 - val_loss: 0.0443 - val_acc: 0.9904 - lr: 1.0000e-06\n",
            "Epoch 143/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1113 - acc: 0.9625\n",
            "Epoch 143: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 8s 512ms/step - loss: 0.1113 - acc: 0.9625 - val_loss: 0.0613 - val_acc: 0.9808 - lr: 1.0000e-06\n",
            "Epoch 144/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0753 - acc: 0.9750\n",
            "Epoch 144: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 8s 510ms/step - loss: 0.0753 - acc: 0.9750 - val_loss: 0.0402 - val_acc: 0.9840 - lr: 1.0000e-06\n",
            "Epoch 145/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1011 - acc: 0.9688\n",
            "Epoch 145: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 438ms/step - loss: 0.1011 - acc: 0.9688 - val_loss: 0.0727 - val_acc: 0.9679 - lr: 1.0000e-06\n",
            "Epoch 146/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0706 - acc: 0.9792\n",
            "Epoch 146: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 8s 500ms/step - loss: 0.0706 - acc: 0.9792 - val_loss: 0.0543 - val_acc: 0.9808 - lr: 1.0000e-06\n",
            "Epoch 147/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0834 - acc: 0.9729\n",
            "Epoch 147: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 8s 512ms/step - loss: 0.0834 - acc: 0.9729 - val_loss: 0.0827 - val_acc: 0.9647 - lr: 1.0000e-07\n",
            "Epoch 148/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0569 - acc: 0.9812\n",
            "Epoch 148: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 438ms/step - loss: 0.0569 - acc: 0.9812 - val_loss: 0.0505 - val_acc: 0.9744 - lr: 1.0000e-07\n",
            "Epoch 149/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0754 - acc: 0.9833\n",
            "Epoch 149: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 441ms/step - loss: 0.0754 - acc: 0.9833 - val_loss: 0.0356 - val_acc: 0.9872 - lr: 1.0000e-07\n",
            "Epoch 150/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0937 - acc: 0.9604\n",
            "Epoch 150: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 8s 508ms/step - loss: 0.0937 - acc: 0.9604 - val_loss: 0.0652 - val_acc: 0.9776 - lr: 1.0000e-07\n",
            "Epoch 151/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0950 - acc: 0.9604\n",
            "Epoch 151: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 439ms/step - loss: 0.0950 - acc: 0.9604 - val_loss: 0.0868 - val_acc: 0.9712 - lr: 1.0000e-07\n",
            "Epoch 152/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0844 - acc: 0.9688\n",
            "Epoch 152: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 440ms/step - loss: 0.0844 - acc: 0.9688 - val_loss: 0.0816 - val_acc: 0.9840 - lr: 1.0000e-07\n",
            "Epoch 153/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1135 - acc: 0.9667\n",
            "Epoch 153: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 470ms/step - loss: 0.1135 - acc: 0.9667 - val_loss: 0.1281 - val_acc: 0.9583 - lr: 1.0000e-07\n",
            "Epoch 154/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.0854 - acc: 0.9750\n",
            "Epoch 154: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 8s 514ms/step - loss: 0.0854 - acc: 0.9750 - val_loss: 0.0588 - val_acc: 0.9808 - lr: 1.0000e-07\n",
            "Epoch 155/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1344 - acc: 0.9604\n",
            "Epoch 155: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 442ms/step - loss: 0.1344 - acc: 0.9604 - val_loss: 0.0676 - val_acc: 0.9776 - lr: 1.0000e-07\n",
            "Epoch 156/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1205 - acc: 0.9563\n",
            "Epoch 156: val_acc did not improve from 0.99679\n",
            "15/15 [==============================] - 7s 441ms/step - loss: 0.1205 - acc: 0.9563 - val_loss: 0.0561 - val_acc: 0.9808 - lr: 1.0000e-07\n",
            "Epoch 156: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightedAverageLayer(tf.keras.layers.Layer):\n",
        "    def _init_(self, w1, w2, **kwargs):\n",
        "        super(WeightedAverageLayer, self)._init_(**kwargs)\n",
        "        self.w1 = w1\n",
        "        self.w2 = w2\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.w1 * inputs[0] + self.w2 * inputs[1]\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'w1': self.w1,\n",
        "            'w2': self.w2,\n",
        "            \n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "VbChPiFSHdut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    import numpy as np\n",
        "    import tensorflow\n",
        "    \n",
        "    # Disable scientific notation for clarity\n",
        "    np.set_printoptions(suppress=True)\n",
        "    \n",
        "    # Load the model\n",
        "    keras_model1 = tensorflow.keras.models.load_model('efficient_weights.h5', compile=False)\n",
        "    keras_model1._name = 'model1'\n",
        "    keras_model2 = tensorflow.keras.models.load_model('98.h5', compile=False)\n",
        "    keras_model2._name = 'model2'\n",
        "    models = [keras_model1, keras_model2]\n",
        "    #model_input = tf.keras.Input(shape=(125, 125, 3))\n",
        "    model_input = tf.keras.Input(shape=(32, 32, 3))\n",
        "    model_outputs = [model(model_input) for model in models]\n",
        "    ensemble_output = 0.7 * model_outputs[0] + 0.3 * model_outputs[1]\n",
        "    ensemble_model = tf.keras.Model(inputs=model_input, outputs=ensemble_output)\n",
        "    ensemble_model.save(\"Ensemble.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27rIbJOLHkt1",
        "outputId": "ba09968b-0b83-4c29-9c94-d0abe0824f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_model=tensorflow.keras.models.load_model('Ensemble.h5', compile=False,custom_objects={\"WeightedAverageLayer\": WeightedAverageLayer })\n",
        "ensemble_model.compile(optimizer=\"Adam\",loss='categorical_crossentropy',metrics=['acc'])"
      ],
      "metadata": {
        "id": "XGkaLSsrHlyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "filepath=\"ensemble_weights.tf\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "history=ensemble_model.fit_generator(train_generator,\n",
        "                              validation_data=val_generator,\n",
        "                              epochs=666,\n",
        "                              callbacks=[checkpoint,reduce_lr,early_stop],\n",
        "                              verbose=1,steps_per_epoch=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyyiTLmgHv8v",
        "outputId": "a79a2ea1-8630-4662-d448-f721d78963d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-66-bd8b9bff2502>:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history=ensemble_model.fit_generator(train_generator,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - ETA: 0s - loss: 0.5560 - acc: 0.9292\n",
            "Epoch 1: val_acc improved from -inf to 0.48718, saving model to ensemble_weights.tf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 83s 5s/step - loss: 0.5560 - acc: 0.9292 - val_loss: 2.0570 - val_acc: 0.4872 - lr: 0.0010\n",
            "Epoch 2/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6209 - acc: 0.8813\n",
            "Epoch 2: val_acc improved from 0.48718 to 0.71795, saving model to ensemble_weights.tf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 71s 5s/step - loss: 0.6209 - acc: 0.8813 - val_loss: 1.1589 - val_acc: 0.7179 - lr: 0.0010\n",
            "Epoch 3/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5602 - acc: 0.9125\n",
            "Epoch 3: val_acc did not improve from 0.71795\n",
            "15/15 [==============================] - 8s 556ms/step - loss: 0.5602 - acc: 0.9125 - val_loss: 1.6456 - val_acc: 0.5385 - lr: 0.0010\n",
            "Epoch 4/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5069 - acc: 0.9146\n",
            "Epoch 4: val_acc improved from 0.71795 to 0.73397, saving model to ensemble_weights.tf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 69s 5s/step - loss: 0.5069 - acc: 0.9146 - val_loss: 1.1133 - val_acc: 0.7340 - lr: 0.0010\n",
            "Epoch 5/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5787 - acc: 0.9000\n",
            "Epoch 5: val_acc did not improve from 0.73397\n",
            "15/15 [==============================] - 8s 563ms/step - loss: 0.5787 - acc: 0.9000 - val_loss: 2.1844 - val_acc: 0.3333 - lr: 0.0010\n",
            "Epoch 6/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5884 - acc: 0.8813\n",
            "Epoch 6: val_acc improved from 0.73397 to 0.74038, saving model to ensemble_weights.tf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 71s 5s/step - loss: 0.5884 - acc: 0.8813 - val_loss: 0.9868 - val_acc: 0.7404 - lr: 0.0010\n",
            "Epoch 7/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4992 - acc: 0.9083\n",
            "Epoch 7: val_acc did not improve from 0.74038\n",
            "15/15 [==============================] - 8s 531ms/step - loss: 0.4992 - acc: 0.9083 - val_loss: 1.2150 - val_acc: 0.6346 - lr: 0.0010\n",
            "Epoch 8/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5128 - acc: 0.9062\n",
            "Epoch 8: val_acc improved from 0.74038 to 0.92308, saving model to ensemble_weights.tf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 70s 5s/step - loss: 0.5128 - acc: 0.9062 - val_loss: 0.4288 - val_acc: 0.9231 - lr: 0.0010\n",
            "Epoch 9/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5115 - acc: 0.9083\n",
            "Epoch 9: val_acc did not improve from 0.92308\n",
            "15/15 [==============================] - 9s 579ms/step - loss: 0.5115 - acc: 0.9083 - val_loss: 0.7477 - val_acc: 0.7692 - lr: 0.0010\n",
            "Epoch 10/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4737 - acc: 0.8979\n",
            "Epoch 10: val_acc did not improve from 0.92308\n",
            "15/15 [==============================] - 9s 585ms/step - loss: 0.4737 - acc: 0.8979 - val_loss: 0.6035 - val_acc: 0.8462 - lr: 0.0010\n",
            "Epoch 11/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4297 - acc: 0.9167\n",
            "Epoch 11: val_acc did not improve from 0.92308\n",
            "15/15 [==============================] - 8s 565ms/step - loss: 0.4297 - acc: 0.9167 - val_loss: 0.9288 - val_acc: 0.6859 - lr: 0.0010\n",
            "Epoch 12/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4242 - acc: 0.9167\n",
            "Epoch 12: val_acc did not improve from 0.92308\n",
            "15/15 [==============================] - 7s 497ms/step - loss: 0.4242 - acc: 0.9167 - val_loss: 0.5075 - val_acc: 0.8878 - lr: 0.0010\n",
            "Epoch 13/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4594 - acc: 0.8854\n",
            "Epoch 13: val_acc did not improve from 0.92308\n",
            "15/15 [==============================] - 8s 510ms/step - loss: 0.4594 - acc: 0.8854 - val_loss: 0.6406 - val_acc: 0.8654 - lr: 0.0010\n",
            "Epoch 14/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4033 - acc: 0.9104\n",
            "Epoch 14: val_acc did not improve from 0.92308\n",
            "15/15 [==============================] - 9s 556ms/step - loss: 0.4033 - acc: 0.9104 - val_loss: 1.5711 - val_acc: 0.4647 - lr: 0.0010\n",
            "Epoch 15/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4574 - acc: 0.8958\n",
            "Epoch 15: val_acc did not improve from 0.92308\n",
            "15/15 [==============================] - 9s 579ms/step - loss: 0.4574 - acc: 0.8958 - val_loss: 1.5565 - val_acc: 0.4776 - lr: 0.0010\n",
            "Epoch 16/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4538 - acc: 0.8979\n",
            "Epoch 16: val_acc did not improve from 0.92308\n",
            "15/15 [==============================] - 9s 581ms/step - loss: 0.4538 - acc: 0.8979 - val_loss: 1.9186 - val_acc: 0.3173 - lr: 0.0010\n",
            "Epoch 17/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4289 - acc: 0.9062\n",
            "Epoch 17: val_acc did not improve from 0.92308\n",
            "15/15 [==============================] - 8s 532ms/step - loss: 0.4289 - acc: 0.9062 - val_loss: 2.3464 - val_acc: 0.1603 - lr: 0.0010\n",
            "Epoch 18/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3665 - acc: 0.9167\n",
            "Epoch 18: val_acc did not improve from 0.92308\n",
            "15/15 [==============================] - 8s 538ms/step - loss: 0.3665 - acc: 0.9167 - val_loss: 0.8556 - val_acc: 0.7564 - lr: 0.0010\n",
            "Epoch 19/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4418 - acc: 0.8979\n",
            "Epoch 19: val_acc did not improve from 0.92308\n",
            "15/15 [==============================] - 9s 581ms/step - loss: 0.4418 - acc: 0.8979 - val_loss: 0.6649 - val_acc: 0.8237 - lr: 0.0010\n",
            "Epoch 20/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4276 - acc: 0.8979\n",
            "Epoch 20: val_acc did not improve from 0.92308\n",
            "15/15 [==============================] - 8s 500ms/step - loss: 0.4276 - acc: 0.8979 - val_loss: 1.1470 - val_acc: 0.6506 - lr: 0.0010\n",
            "Epoch 21/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3615 - acc: 0.9271\n",
            "Epoch 21: val_acc did not improve from 0.92308\n",
            "15/15 [==============================] - 8s 505ms/step - loss: 0.3615 - acc: 0.9271 - val_loss: 1.3345 - val_acc: 0.5513 - lr: 0.0010\n",
            "Epoch 22/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3671 - acc: 0.9208\n",
            "Epoch 22: val_acc did not improve from 0.92308\n",
            "15/15 [==============================] - 9s 582ms/step - loss: 0.3671 - acc: 0.9208 - val_loss: 1.5781 - val_acc: 0.3590 - lr: 0.0010\n",
            "Epoch 23/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3132 - acc: 0.9500\n",
            "Epoch 23: val_acc did not improve from 0.92308\n",
            "15/15 [==============================] - 9s 583ms/step - loss: 0.3132 - acc: 0.9500 - val_loss: 0.9224 - val_acc: 0.7083 - lr: 0.0010\n",
            "Epoch 24/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3718 - acc: 0.9104\n",
            "Epoch 24: val_acc did not improve from 0.92308\n",
            "15/15 [==============================] - 8s 505ms/step - loss: 0.3718 - acc: 0.9104 - val_loss: 0.3674 - val_acc: 0.9006 - lr: 1.0000e-04\n",
            "Epoch 25/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3549 - acc: 0.9146\n",
            "Epoch 25: val_acc improved from 0.92308 to 0.94551, saving model to ensemble_weights.tf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 74s 5s/step - loss: 0.3549 - acc: 0.9146 - val_loss: 0.2337 - val_acc: 0.9455 - lr: 1.0000e-04\n",
            "Epoch 26/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3516 - acc: 0.9146\n",
            "Epoch 26: val_acc did not improve from 0.94551\n",
            "15/15 [==============================] - 8s 517ms/step - loss: 0.3516 - acc: 0.9146 - val_loss: 0.2617 - val_acc: 0.9455 - lr: 1.0000e-04\n",
            "Epoch 27/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2678 - acc: 0.9438\n",
            "Epoch 27: val_acc did not improve from 0.94551\n",
            "15/15 [==============================] - 9s 555ms/step - loss: 0.2678 - acc: 0.9438 - val_loss: 0.2829 - val_acc: 0.9327 - lr: 1.0000e-04\n",
            "Epoch 28/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2633 - acc: 0.9583\n",
            "Epoch 28: val_acc improved from 0.94551 to 0.96154, saving model to ensemble_weights.tf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 75s 5s/step - loss: 0.2633 - acc: 0.9583 - val_loss: 0.2203 - val_acc: 0.9615 - lr: 1.0000e-04\n",
            "Epoch 29/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2866 - acc: 0.9333\n",
            "Epoch 29: val_acc did not improve from 0.96154\n",
            "15/15 [==============================] - 9s 580ms/step - loss: 0.2866 - acc: 0.9333 - val_loss: 0.2180 - val_acc: 0.9615 - lr: 1.0000e-04\n",
            "Epoch 30/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3060 - acc: 0.9396\n",
            "Epoch 30: val_acc improved from 0.96154 to 0.97436, saving model to ensemble_weights.tf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 72s 5s/step - loss: 0.3060 - acc: 0.9396 - val_loss: 0.1907 - val_acc: 0.9744 - lr: 1.0000e-04\n",
            "Epoch 31/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2310 - acc: 0.9563\n",
            "Epoch 31: val_acc improved from 0.97436 to 0.97756, saving model to ensemble_weights.tf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 74s 5s/step - loss: 0.2310 - acc: 0.9563 - val_loss: 0.1672 - val_acc: 0.9776 - lr: 1.0000e-04\n",
            "Epoch 32/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.3044 - acc: 0.9312\n",
            "Epoch 32: val_acc did not improve from 0.97756\n",
            "15/15 [==============================] - 9s 580ms/step - loss: 0.3044 - acc: 0.9312 - val_loss: 0.2134 - val_acc: 0.9712 - lr: 1.0000e-04\n",
            "Epoch 33/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2175 - acc: 0.9521\n",
            "Epoch 33: val_acc did not improve from 0.97756\n",
            "15/15 [==============================] - 9s 580ms/step - loss: 0.2175 - acc: 0.9521 - val_loss: 0.1861 - val_acc: 0.9712 - lr: 1.0000e-04\n",
            "Epoch 34/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2261 - acc: 0.9625\n",
            "Epoch 34: val_acc did not improve from 0.97756\n",
            "15/15 [==============================] - 8s 505ms/step - loss: 0.2261 - acc: 0.9625 - val_loss: 0.1977 - val_acc: 0.9712 - lr: 1.0000e-04\n",
            "Epoch 35/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2247 - acc: 0.9604\n",
            "Epoch 35: val_acc did not improve from 0.97756\n",
            "15/15 [==============================] - 8s 515ms/step - loss: 0.2247 - acc: 0.9604 - val_loss: 0.2670 - val_acc: 0.9519 - lr: 1.0000e-04\n",
            "Epoch 36/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2797 - acc: 0.9354\n",
            "Epoch 36: val_acc did not improve from 0.97756\n",
            "15/15 [==============================] - 9s 608ms/step - loss: 0.2797 - acc: 0.9354 - val_loss: 0.2098 - val_acc: 0.9647 - lr: 1.0000e-04\n",
            "Epoch 37/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2447 - acc: 0.9396\n",
            "Epoch 37: val_acc did not improve from 0.97756\n",
            "15/15 [==============================] - 9s 591ms/step - loss: 0.2447 - acc: 0.9396 - val_loss: 0.1793 - val_acc: 0.9744 - lr: 1.0000e-04\n",
            "Epoch 38/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2254 - acc: 0.9542\n",
            "Epoch 38: val_acc did not improve from 0.97756\n",
            "15/15 [==============================] - 7s 500ms/step - loss: 0.2254 - acc: 0.9542 - val_loss: 0.2297 - val_acc: 0.9487 - lr: 1.0000e-04\n",
            "Epoch 39/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2503 - acc: 0.9521\n",
            "Epoch 39: val_acc improved from 0.97756 to 0.98397, saving model to ensemble_weights.tf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 74s 5s/step - loss: 0.2503 - acc: 0.9521 - val_loss: 0.1752 - val_acc: 0.9840 - lr: 1.0000e-04\n",
            "Epoch 40/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2156 - acc: 0.9604\n",
            "Epoch 40: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 9s 582ms/step - loss: 0.2156 - acc: 0.9604 - val_loss: 0.2179 - val_acc: 0.9583 - lr: 1.0000e-04\n",
            "Epoch 41/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2240 - acc: 0.9542\n",
            "Epoch 41: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 8s 511ms/step - loss: 0.2240 - acc: 0.9542 - val_loss: 0.2229 - val_acc: 0.9679 - lr: 1.0000e-04\n",
            "Epoch 42/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1819 - acc: 0.9688\n",
            "Epoch 42: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 9s 560ms/step - loss: 0.1819 - acc: 0.9688 - val_loss: 0.2241 - val_acc: 0.9583 - lr: 1.0000e-04\n",
            "Epoch 43/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2131 - acc: 0.9604\n",
            "Epoch 43: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 9s 586ms/step - loss: 0.2131 - acc: 0.9604 - val_loss: 0.2082 - val_acc: 0.9647 - lr: 1.0000e-04\n",
            "Epoch 44/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1941 - acc: 0.9583\n",
            "Epoch 44: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 8s 568ms/step - loss: 0.1941 - acc: 0.9583 - val_loss: 0.1461 - val_acc: 0.9840 - lr: 1.0000e-04\n",
            "Epoch 45/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1946 - acc: 0.9646\n",
            "Epoch 45: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 491ms/step - loss: 0.1946 - acc: 0.9646 - val_loss: 0.1747 - val_acc: 0.9776 - lr: 1.0000e-04\n",
            "Epoch 46/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2224 - acc: 0.9625\n",
            "Epoch 46: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 489ms/step - loss: 0.2224 - acc: 0.9625 - val_loss: 0.2051 - val_acc: 0.9712 - lr: 1.0000e-04\n",
            "Epoch 47/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1970 - acc: 0.9604\n",
            "Epoch 47: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 8s 571ms/step - loss: 0.1970 - acc: 0.9604 - val_loss: 0.2128 - val_acc: 0.9679 - lr: 1.0000e-04\n",
            "Epoch 48/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2046 - acc: 0.9479\n",
            "Epoch 48: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 8s 537ms/step - loss: 0.2046 - acc: 0.9479 - val_loss: 0.2138 - val_acc: 0.9647 - lr: 1.0000e-04\n",
            "Epoch 49/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1974 - acc: 0.9708\n",
            "Epoch 49: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 8s 522ms/step - loss: 0.1974 - acc: 0.9708 - val_loss: 0.2036 - val_acc: 0.9615 - lr: 1.0000e-04\n",
            "Epoch 50/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2139 - acc: 0.9583\n",
            "Epoch 50: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 8s 566ms/step - loss: 0.2139 - acc: 0.9583 - val_loss: 0.1599 - val_acc: 0.9776 - lr: 1.0000e-04\n",
            "Epoch 51/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2079 - acc: 0.9646\n",
            "Epoch 51: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 8s 574ms/step - loss: 0.2079 - acc: 0.9646 - val_loss: 0.2442 - val_acc: 0.9423 - lr: 1.0000e-04\n",
            "Epoch 52/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1918 - acc: 0.9646\n",
            "Epoch 52: val_acc did not improve from 0.98397\n",
            "15/15 [==============================] - 7s 492ms/step - loss: 0.1918 - acc: 0.9646 - val_loss: 0.2106 - val_acc: 0.9615 - lr: 1.0000e-04\n",
            "Epoch 53/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1651 - acc: 0.9750\n",
            "Epoch 53: val_acc improved from 0.98397 to 0.98718, saving model to ensemble_weights.tf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 76s 5s/step - loss: 0.1651 - acc: 0.9750 - val_loss: 0.1550 - val_acc: 0.9872 - lr: 1.0000e-04\n",
            "Epoch 54/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1817 - acc: 0.9625\n",
            "Epoch 54: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 9s 584ms/step - loss: 0.1817 - acc: 0.9625 - val_loss: 0.2142 - val_acc: 0.9583 - lr: 1.0000e-04\n",
            "Epoch 55/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2285 - acc: 0.9542\n",
            "Epoch 55: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 8s 531ms/step - loss: 0.2285 - acc: 0.9542 - val_loss: 0.1782 - val_acc: 0.9744 - lr: 1.0000e-04\n",
            "Epoch 56/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2042 - acc: 0.9667\n",
            "Epoch 56: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 8s 504ms/step - loss: 0.2042 - acc: 0.9667 - val_loss: 0.1900 - val_acc: 0.9744 - lr: 1.0000e-04\n",
            "Epoch 57/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1916 - acc: 0.9688\n",
            "Epoch 57: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 8s 519ms/step - loss: 0.1916 - acc: 0.9688 - val_loss: 0.1840 - val_acc: 0.9776 - lr: 1.0000e-04\n",
            "Epoch 58/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2148 - acc: 0.9583\n",
            "Epoch 58: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 9s 574ms/step - loss: 0.2148 - acc: 0.9583 - val_loss: 0.1849 - val_acc: 0.9647 - lr: 1.0000e-04\n",
            "Epoch 59/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1687 - acc: 0.9771\n",
            "Epoch 59: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 9s 582ms/step - loss: 0.1687 - acc: 0.9771 - val_loss: 0.1779 - val_acc: 0.9647 - lr: 1.0000e-04\n",
            "Epoch 60/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2005 - acc: 0.9667\n",
            "Epoch 60: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 8s 560ms/step - loss: 0.2005 - acc: 0.9667 - val_loss: 0.1442 - val_acc: 0.9872 - lr: 1.0000e-05\n",
            "Epoch 61/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1711 - acc: 0.9792\n",
            "Epoch 61: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 8s 503ms/step - loss: 0.1711 - acc: 0.9792 - val_loss: 0.1939 - val_acc: 0.9647 - lr: 1.0000e-05\n",
            "Epoch 62/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1960 - acc: 0.9667\n",
            "Epoch 62: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 9s 583ms/step - loss: 0.1960 - acc: 0.9667 - val_loss: 0.1881 - val_acc: 0.9712 - lr: 1.0000e-05\n",
            "Epoch 63/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1820 - acc: 0.9708\n",
            "Epoch 63: val_acc did not improve from 0.98718\n",
            "15/15 [==============================] - 9s 578ms/step - loss: 0.1820 - acc: 0.9708 - val_loss: 0.1909 - val_acc: 0.9744 - lr: 1.0000e-05\n",
            "Epoch 64/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1928 - acc: 0.9625\n",
            "Epoch 64: val_acc improved from 0.98718 to 0.99038, saving model to ensemble_weights.tf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 74s 5s/step - loss: 0.1928 - acc: 0.9625 - val_loss: 0.1350 - val_acc: 0.9904 - lr: 1.0000e-05\n",
            "Epoch 65/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2247 - acc: 0.9625\n",
            "Epoch 65: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 9s 580ms/step - loss: 0.2247 - acc: 0.9625 - val_loss: 0.1845 - val_acc: 0.9712 - lr: 1.0000e-05\n",
            "Epoch 66/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2295 - acc: 0.9521\n",
            "Epoch 66: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 9s 584ms/step - loss: 0.2295 - acc: 0.9521 - val_loss: 0.1678 - val_acc: 0.9712 - lr: 1.0000e-05\n",
            "Epoch 67/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1902 - acc: 0.9729\n",
            "Epoch 67: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 8s 521ms/step - loss: 0.1902 - acc: 0.9729 - val_loss: 0.1447 - val_acc: 0.9776 - lr: 1.0000e-05\n",
            "Epoch 68/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2014 - acc: 0.9542\n",
            "Epoch 68: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 9s 557ms/step - loss: 0.2014 - acc: 0.9542 - val_loss: 0.1775 - val_acc: 0.9647 - lr: 1.0000e-05\n",
            "Epoch 69/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2142 - acc: 0.9688\n",
            "Epoch 69: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 9s 581ms/step - loss: 0.2142 - acc: 0.9688 - val_loss: 0.2102 - val_acc: 0.9615 - lr: 1.0000e-05\n",
            "Epoch 70/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1981 - acc: 0.9604\n",
            "Epoch 70: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 9s 577ms/step - loss: 0.1981 - acc: 0.9604 - val_loss: 0.2139 - val_acc: 0.9647 - lr: 1.0000e-05\n",
            "Epoch 71/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2082 - acc: 0.9667\n",
            "Epoch 71: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 8s 505ms/step - loss: 0.2082 - acc: 0.9667 - val_loss: 0.1733 - val_acc: 0.9647 - lr: 1.0000e-05\n",
            "Epoch 72/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1743 - acc: 0.9750\n",
            "Epoch 72: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 8s 500ms/step - loss: 0.1743 - acc: 0.9750 - val_loss: 0.1679 - val_acc: 0.9712 - lr: 1.0000e-05\n",
            "Epoch 73/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2049 - acc: 0.9521\n",
            "Epoch 73: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 9s 558ms/step - loss: 0.2049 - acc: 0.9521 - val_loss: 0.1916 - val_acc: 0.9744 - lr: 1.0000e-05\n",
            "Epoch 74/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1698 - acc: 0.9708\n",
            "Epoch 74: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 9s 575ms/step - loss: 0.1698 - acc: 0.9708 - val_loss: 0.1730 - val_acc: 0.9744 - lr: 1.0000e-05\n",
            "Epoch 75/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1963 - acc: 0.9667\n",
            "Epoch 75: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 9s 576ms/step - loss: 0.1963 - acc: 0.9667 - val_loss: 0.1754 - val_acc: 0.9712 - lr: 1.0000e-05\n",
            "Epoch 76/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1761 - acc: 0.9667\n",
            "Epoch 76: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 7s 501ms/step - loss: 0.1761 - acc: 0.9667 - val_loss: 0.1610 - val_acc: 0.9840 - lr: 1.0000e-05\n",
            "Epoch 77/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1944 - acc: 0.9771\n",
            "Epoch 77: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 9s 573ms/step - loss: 0.1944 - acc: 0.9771 - val_loss: 0.2131 - val_acc: 0.9744 - lr: 1.0000e-05\n",
            "Epoch 78/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2013 - acc: 0.9667\n",
            "Epoch 78: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 9s 585ms/step - loss: 0.2013 - acc: 0.9667 - val_loss: 0.1683 - val_acc: 0.9712 - lr: 1.0000e-05\n",
            "Epoch 79/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1788 - acc: 0.9604\n",
            "Epoch 79: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 8s 509ms/step - loss: 0.1788 - acc: 0.9604 - val_loss: 0.1514 - val_acc: 0.9872 - lr: 1.0000e-05\n",
            "Epoch 80/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2226 - acc: 0.9479\n",
            "Epoch 80: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 8s 508ms/step - loss: 0.2226 - acc: 0.9479 - val_loss: 0.2010 - val_acc: 0.9712 - lr: 1.0000e-06\n",
            "Epoch 81/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2124 - acc: 0.9604\n",
            "Epoch 81: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 8s 520ms/step - loss: 0.2124 - acc: 0.9604 - val_loss: 0.1642 - val_acc: 0.9808 - lr: 1.0000e-06\n",
            "Epoch 82/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2284 - acc: 0.9625\n",
            "Epoch 82: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 9s 585ms/step - loss: 0.2284 - acc: 0.9625 - val_loss: 0.1687 - val_acc: 0.9647 - lr: 1.0000e-06\n",
            "Epoch 83/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1771 - acc: 0.9750\n",
            "Epoch 83: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 9s 585ms/step - loss: 0.1771 - acc: 0.9750 - val_loss: 0.2039 - val_acc: 0.9647 - lr: 1.0000e-06\n",
            "Epoch 84/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1989 - acc: 0.9646\n",
            "Epoch 84: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 8s 511ms/step - loss: 0.1989 - acc: 0.9646 - val_loss: 0.1741 - val_acc: 0.9744 - lr: 1.0000e-06\n",
            "Epoch 85/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1826 - acc: 0.9771\n",
            "Epoch 85: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 9s 581ms/step - loss: 0.1826 - acc: 0.9771 - val_loss: 0.1571 - val_acc: 0.9744 - lr: 1.0000e-06\n",
            "Epoch 86/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1896 - acc: 0.9542\n",
            "Epoch 86: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 9s 598ms/step - loss: 0.1896 - acc: 0.9542 - val_loss: 0.1573 - val_acc: 0.9808 - lr: 1.0000e-06\n",
            "Epoch 87/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1816 - acc: 0.9729\n",
            "Epoch 87: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 8s 509ms/step - loss: 0.1816 - acc: 0.9729 - val_loss: 0.1654 - val_acc: 0.9808 - lr: 1.0000e-06\n",
            "Epoch 88/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2187 - acc: 0.9583\n",
            "Epoch 88: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 8s 505ms/step - loss: 0.2187 - acc: 0.9583 - val_loss: 0.1471 - val_acc: 0.9840 - lr: 1.0000e-06\n",
            "Epoch 89/666\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.1962 - acc: 0.9667\n",
            "Epoch 89: val_acc did not improve from 0.99038\n",
            "15/15 [==============================] - 8s 546ms/step - loss: 0.1962 - acc: 0.9667 - val_loss: 0.1675 - val_acc: 0.9776 - lr: 1.0000e-06\n",
            "Epoch 89: early stopping\n"
          ]
        }
      ]
    }
  ]
}